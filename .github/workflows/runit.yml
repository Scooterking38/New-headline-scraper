name: Selenium Scraper

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  scraper:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python 3.9
        uses: actions/setup-python@v3
        with:
          python-version: 3.9

      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Install dependencies
        run: python -m pip install --upgrade pip
      - run: python -m pip install -r requirements.txt

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install selenium beautifulsoup4

      - name: Install Google Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y wget curl
          wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
          sudo dpkg -i google-chrome-stable_current_amd64.deb
          sudo apt-get install -f

      - name: Setup Chromedriver
        uses: nanasess/setup-chromedriver@v2.3.0
        with:
          chrome-version: stable  # automatically matches your installed Chrome

      - name: Run scraper script
        run: python news_scraper.py

      - name: Commit and push headlines
        run: |
          if [ -f headlines.txt ]; then
            git config --global user.name "GitHub Actions"
            git config --global user.email "actions@github.com"
            git add headlines.txt
            git commit -m "Add scraped headlines"
            git push
          else
            echo "No headlines found or saved."
